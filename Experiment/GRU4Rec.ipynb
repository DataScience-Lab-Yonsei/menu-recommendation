{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqTQWTGWqGfF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "539c8e42-2b07-40d7-9a62-4e346fcb3558"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "Rx2_jXkVqR2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "i7XN7zDcqL8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/Shareddrives/DSL_Modeling_B/data/menu_final.csv', index_col=0).reset_index(drop=True)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "QWn4E1hbqW6n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "7aea91ff-7030-4ea6-e97d-1723d97449cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   SessionID   Menu  MenuID  timestamp\n",
              "0          0     찐빵     0.0          1\n",
              "1          0  오징어찌개     1.0          2\n",
              "2          0    육개장     2.0          3\n",
              "3          0  단호박샌드     3.0          4\n",
              "4          0   김치찌개     4.0          5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6fdf752c-8a8b-4790-a622-4f4d294ac352\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SessionID</th>\n",
              "      <th>Menu</th>\n",
              "      <th>MenuID</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>찐빵</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>오징어찌개</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>육개장</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>단호박샌드</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>김치찌개</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6fdf752c-8a8b-4790-a622-4f4d294ac352')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6fdf752c-8a8b-4790-a622-4f4d294ac352 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6fdf752c-8a8b-4790-a622-4f4d294ac352');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del data['MenuID']\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5qFuHLVHqa0X",
        "outputId": "9254a50b-ce4d-4cce-9365-fb6889f3089d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   SessionID   Menu  timestamp\n",
              "0          0     찐빵          1\n",
              "1          0  오징어찌개          2\n",
              "2          0    육개장          3\n",
              "3          0  단호박샌드          4\n",
              "4          0   김치찌개          5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-190fbb3f-d358-4a0e-8a64-d7d5013d1ead\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SessionID</th>\n",
              "      <th>Menu</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>찐빵</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>오징어찌개</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>육개장</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>단호박샌드</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>김치찌개</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-190fbb3f-d358-4a0e-8a64-d7d5013d1ead')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-190fbb3f-d358-4a0e-8a64-d7d5013d1ead button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-190fbb3f-d358-4a0e-8a64-d7d5013d1ead');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# error 발생시키는 값 처리\n",
        "data.iloc[135569, 1] = '수제비'\n",
        "data.iloc[135809, 1] = '계란국'"
      ],
      "metadata": {
        "id": "8fLpdNzNqcWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 컬럼명 변경\n",
        "data.rename(columns={'SessionID':'session', 'Menu':'item'}, inplace=True)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LV6r9nUbqfDk",
        "outputId": "292d7127-a660-4c5f-8ec4-47d79213f9ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   session   item  timestamp\n",
              "0        0     찐빵          1\n",
              "1        0  오징어찌개          2\n",
              "2        0    육개장          3\n",
              "3        0  단호박샌드          4\n",
              "4        0   김치찌개          5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eca1ba9b-93af-4c4d-882d-d875848b2cc8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>session</th>\n",
              "      <th>item</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>찐빵</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>오징어찌개</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>육개장</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>단호박샌드</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>김치찌개</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eca1ba9b-93af-4c4d-882d-d875848b2cc8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eca1ba9b-93af-4c4d-882d-d875848b2cc8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eca1ba9b-93af-4c4d-882d-d875848b2cc8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# session별 history\n",
        "history = data.groupby('session').item.apply(list)\n",
        "history.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qq4L1MUHqgZp",
        "outputId": "eba6f25a-fc0c-423b-a62b-a796db4db01e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "session\n",
              "0    [찐빵, 오징어찌개, 육개장, 단호박샌드, 김치찌개, 어묵국, 베이글, 팽이장국, ...\n",
              "1    [인절미토스트, 유부장국, 순두부찌개, 씨크립샌드, 대구찌개, 설렁탕, 팬케익, 쇠...\n",
              "2    [사과파이, 부대찌개, 오징어국, 브라우니, 콩나물국, 대구찌개, 고구마샌드, 차돌...\n",
              "3    [크로와상, 시금치국, 닭곰탕, 마늘빵, 꽃게탕, 수제비국, 씨크립샌드, 쇠고기샤브...\n",
              "4    [야채샌드, 버섯들깨탕, 쇠고기미역국, 팬케익, 순두부찌개, 된장찌개, 단호박샌드,...\n",
              "Name: item, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "V6OrilkKqvX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "rWLRveUCqsl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "v-BODd3CqyLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SessionDataset:\n",
        "\n",
        "      def __init__(self, df):\n",
        "\n",
        "          self.df = df.sort_values(by = ['session', 'timestamp']).reset_index(drop = True) # session (int) | timestamp (int) | item (string)\n",
        "          self.offsets    = np.concatenate((np.zeros(1, dtype = np.int32), self.df.groupby('session').size().cumsum().values)) # indices in df where the sessions start\n",
        "          self.n_sessions = len(self.offsets) - 1\n",
        "\n",
        "          self.item_to_id = {item : i for i, item in enumerate(self.df.item.unique())}\n",
        "\n",
        "          self.n_items = len(self.item_to_id)\n",
        "\n",
        "      def item_to_one_hot(self, item):\n",
        "\n",
        "          return tf.one_hot(self.item_to_id[item], depth = self.n_items)\n",
        "\n",
        "      def extract_session(self, i, one_hot_encoded = True):\n",
        "\n",
        "          session = self.df[self.offsets[i]:self.offsets[i+1]].copy()\n",
        "          if one_hot_encoded:\n",
        "              session.loc[:, 'item'] = session.item.apply(lambda x : self.item_to_one_hot(x))\n",
        "          return session.item.values.tolist()"
      ],
      "metadata": {
        "id": "8Z5afYAnqxV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss functions: TOP1 and BPR"
      ],
      "metadata": {
        "id": "aZrCSDvCq8ZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# y_true = (BATCH_SIZE, n_classes)   one-hot representations of the target items (ground truths)\n",
        "# y_pred = (BATCH_SIZE, n_classes)   model output = next item scores (logits) for each item in the batch\n",
        "\n",
        "sampling = True\n",
        "\n",
        "if sampling: # = the negative items considered in the loss computation are those within the same batch\n",
        "    \n",
        "    def BPR(y_true, y_pred):\n",
        "        to_lookup = tf.argmax(y_true, axis = 1)   # = indices of the target items\n",
        "        scores = tf.nn.embedding_lookup(tf.transpose(y_pred), to_lookup)  # embedding_lookup is the same as \"extract_rows\". In this way, the positive items end up on the diagonal\n",
        "        return tf.reduce_mean(-tf.math.log(tf.nn.sigmoid(tf.linalg.diag_part(scores) - scores)))\n",
        "\n",
        "    def TOP1(y_true, y_pred):\n",
        "        to_lookup = tf.argmax(y_true, axis = 1)\n",
        "        scores = tf.nn.embedding_lookup(tf.transpose(y_pred), to_lookup)\n",
        "        diag_scores = tf.linalg.diag_part(scores)\n",
        "        loss_by_sample  = tf.reduce_mean(tf.nn.sigmoid(scores - diag_scores) + tf.nn.sigmoid(tf.square(scores)), axis = 0)\n",
        "        loss_by_sample -= tf.nn.sigmoid(tf.square(diag_scores)) / tf.reduce_sum(tf.ones_like(diag_scores)) # only sigmoids of squares of negative items had to be added: remove those of positive items\n",
        "        return tf.reduce_mean(loss_by_sample)\n",
        "\n",
        "else: # = consider all negative items in the loss computation (only makes sense if the number of items is small, like the same order as the batch size)\n",
        "\n",
        "    def BPR(y_true, y_pred):  # both inputs have shape (BATCH_SIZE, n_classes)\n",
        "        _y_pred = tf.expand_dims(y_pred, axis = -1)  # (BATCH_SIZE, n_classes, 1) \n",
        "        mat = tf.matmul(tf.expand_dims(tf.ones_like(y_true), -1), tf.expand_dims(y_true, axis = 1)) # (BATCH_SIZE, n_classes, 1) x (BATCH_SIZE, 1, n_classes) = (BATCH_SIZE, n_classes, n_classes)\n",
        "        score_diffs = tf.matmul(mat, _y_pred) # (BATCH_SIZE, n_classes, n_classes) x (BATCH_SIZE, n_classes, 1) = (BATCH_SIZE, n_classes, 1)\n",
        "        score_diffs = tf.squeeze(score_diffs - _y_pred, -1) # (BATCH_SIZE, n_classes)\n",
        "        return -tf.reduce_sum(tf.math.log(tf.nn.sigmoid(score_diffs)))\n",
        "\n",
        "    def TOP1(y_true, y_pred):\n",
        "        _y_pred = tf.expand_dims(y_pred, axis = -1)  # (BATCH_SIZE, n_classes) ---> (BATCH_SIZE, n_classes, 1) \n",
        "        mat = tf.matmul(tf.expand_dims(tf.ones_like(y_true), -1), tf.expand_dims(y_true, axis = 1)) # (BATCH_SIZE, n_classes, 1) x (BATCH_SIZE, 1, n_classes) --> (BATCH_SIZE, n_classes, n_classes)\n",
        "        score_diffs = tf.matmul(mat, _y_pred) # (BATCH_SIZE, n_classes, n_classes) x (BATCH_SIZE, n_classes, 1) --> (BATCH_SIZE, n_classes, 1)\n",
        "        score_diffs = tf.squeeze(score_diffs - _y_pred, -1) # (BATCH_SIZE, n_classes)\n",
        "        loss_by_sample = tf.reduce_sum(tf.nn.sigmoid(tf.square(y_pred)), axis = -1) + \\\n",
        "                          tf.reduce_sum(tf.sigmoid(-score_diffs), axis = -1) + \\\n",
        "                        -tf.squeeze(tf.squeeze(tf.nn.sigmoid(tf.square(tf.matmul(tf.expand_dims(y_true, 1), _y_pred))), -1), -1)\n",
        "        return tf.reduce_sum(loss_by_sample)"
      ],
      "metadata": {
        "id": "vdRSOTaEq7hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model: GRU4Rec"
      ],
      "metadata": {
        "id": "Bj5C0XrYrAIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Gru4Rec:\n",
        "\n",
        "    def __init__(self, n_classes, n_layers = 1, n_hidden = 64, loss = TOP1, batch_size = 10):\n",
        "\n",
        "        self.n_classes  = n_classes   # = number of items\n",
        "\n",
        "        self.n_layers = n_layers  # number of stacked GRU layers\n",
        "        self.n_hidden = n_hidden  # dimension of GRU cell's hidden state\n",
        "        self.loss     = loss\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.model = self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "\n",
        "        model = tf.keras.models.Sequential()\n",
        "        for i in range(self.n_layers):\n",
        "            model.add(tf.keras.layers.GRU(name = 'GRU_{}'.format(i+1),\n",
        "                                          units      = self.n_hidden, \n",
        "                                          activation = 'relu', \n",
        "                                          stateful   = True,\n",
        "                                          return_sequences = (i < self.n_layers - 1)))\n",
        "        model.add(tf.keras.layers.Dense(units = self.n_classes, activation = 'linear'))   # class logits\n",
        "\n",
        "        # track top 3 accuracy (= how often the true item is among the top 3 recommended)\n",
        "        top3accuracy = lambda y_true, y_pred: tf.keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k = 3)\n",
        "        top3accuracy.__name__ = 'top3accuracy'\n",
        "        model.compile(loss = self.loss, optimizer = 'adam', metrics = ['accuracy', top3accuracy])\n",
        "\n",
        "        model.build(input_shape = (self.batch_size, 1, self.n_classes))\n",
        "        print(model.summary())\n",
        "\n",
        "        return model\n",
        "\n",
        "    def _reset_hidden(self, i):\n",
        "\n",
        "        for nl, layer in enumerate(self.model.layers):   # session has changed: reset corresponding hidden state\n",
        "            if self._is_GRU_layer(layer) and layer.states[0] is not None:\n",
        "                hidden_updated = layer.states[0].numpy()\n",
        "                hidden_updated[i, :] = 0.\n",
        "                self.model.layers[nl].reset_states(hidden_updated)\n",
        "\n",
        "    def _is_GRU_layer(self, layer):\n",
        "\n",
        "        return layer.name.startswith('GRU_')\n",
        "\n",
        "    def train_batch_generator(self, dataset):  # session | item | timestamp\n",
        "        # generates batches of training data X, y = session item, next session item\n",
        "\n",
        "        assert dataset.n_sessions > self.batch_size, \"Training set is too small. Reduce batch size or collect more training data\"\n",
        "        ixs = np.arange(dataset.n_sessions)\n",
        "\n",
        "        stacks = [[]] * self.batch_size   # stacks containing batch_size REVERSED (pieces of) sessions at once. Will be emptied progressively\n",
        "        next_session_id = 0\n",
        "\n",
        "        X, y = np.empty(shape = (self.batch_size, 1, self.n_classes)), np.empty(shape = (self.batch_size, self.n_classes))    \n",
        "        while True:\n",
        "            X[:], y[:] = None, None\n",
        "            for i in range(self.batch_size): # fill in X, y (current batch)\n",
        "                # 1. If stack i is empty (only happens at first round) or has only one element: fill it with a new session\n",
        "                if len(stacks[i]) <= 1:\n",
        "                    if next_session_id >= dataset.n_sessions: # no more sessions available: shuffle sessions and restart\n",
        "                        np.random.shuffle(ixs)\n",
        "                        next_session_id = 0\n",
        "                    while not len(stacks[i]) >= 2:   # ignore sessions with only one element (cannot contribute to the training)\n",
        "                        stacks[i] = dataset.extract_session(ixs[next_session_id])[::-1]  # the data does not have to be all in memory at the same time: we could e.g. load a session at once\n",
        "                        next_session_id += 1\n",
        "                    self._reset_hidden(i)   # if session changes, the corresponding hidden state must be reset\n",
        "                # 2. Stack i is now valid: set input + target variables\n",
        "                X[i, 0] = stacks[i].pop()\n",
        "                y[i]    = stacks[i][-1]\n",
        "\n",
        "            yield tf.constant(X, dtype = tf.float32), tf.constant(y, dtype = tf.float32)\n",
        "\n",
        "    def fit(self, dataset, steps_per_epoch = 10000, epochs = 50):\n",
        "\n",
        "        checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath = \"gru-chkpt-{epoch:02d}.hdf5\")\n",
        "        self.model.fit_generator(generator       = self.train_batch_generator(dataset), \n",
        "                                 steps_per_epoch = steps_per_epoch, \n",
        "                                 epochs          = epochs,\n",
        "                                 callbacks       = [checkpoint], \n",
        "                                 shuffle         = False)"
      ],
      "metadata": {
        "id": "AiyZs9oWq_gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "4Cp8XiIurGBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = data.sort_values(by = ['session', 'timestamp']).reset_index(drop = True)\n",
        "offsets = np.concatenate((np.zeros(1, dtype = np.int32), df.groupby('session').size().cumsum().values))\n",
        "\n",
        "dataset_train = SessionDataset(df.iloc[~df.index.isin(offsets[1:] - 1)])  # training set: remove last element from each session\n",
        "\n",
        "# Test set: x = penultimate item in each session, y = last item in each session\n",
        "X_test = df.iloc[offsets[1:] - 2][['session', 'item']].sort_values(by = ['session']).reset_index(drop = True)\n",
        "y_test = df.iloc[offsets[1:] - 1][['session', 'item']].sort_values(by = ['session']).reset_index(drop = True)\n",
        "\n",
        "print(\"X_test\")\n",
        "print(X_test.head())\n",
        "print('')\n",
        "print(\"y_test\")\n",
        "print(y_test.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgchsEwHrFYS",
        "outputId": "367a795a-a7ec-4c25-b784-5ba16de52c18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test\n",
            "   session    item\n",
            "0        0   냉이된장국\n",
            "1        1   근대된장국\n",
            "2        2  사골우거지국\n",
            "3        3  매운콩나물국\n",
            "4        4  냉이된장찌개\n",
            "\n",
            "y_test\n",
            "   session   item\n",
            "0        0    맑은국\n",
            "1        1     우동\n",
            "2        2  양송이스프\n",
            "3        3   잔치국수\n",
            "4        4  들깨미역국\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g4r = Gru4Rec(n_classes = dataset_train.n_items)\n",
        "g4r.fit(dataset_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rr67eHDsrMeQ",
        "outputId": "0db13898-a925-48be-9458-6266a3810e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer GRU_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " GRU_1 (GRU)                 (10, 64)                  472896    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (10, 2397)                155805    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 628,701\n",
            "Trainable params: 628,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:82: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Epoch 1/50\n",
            "10000/10000 [==============================] - 78s 8ms/step - loss: 0.9172 - accuracy: 0.0162 - top3accuracy: 0.0334\n",
            "Epoch 2/50\n",
            "10000/10000 [==============================] - 77s 8ms/step - loss: 0.8404 - accuracy: 0.0607 - top3accuracy: 0.1245\n",
            "Epoch 3/50\n",
            "10000/10000 [==============================] - 77s 8ms/step - loss: 0.7945 - accuracy: 0.0893 - top3accuracy: 0.2021\n",
            "Epoch 4/50\n",
            "10000/10000 [==============================] - 78s 8ms/step - loss: 0.7853 - accuracy: 0.0915 - top3accuracy: 0.2185\n",
            "Epoch 5/50\n",
            "10000/10000 [==============================] - 79s 8ms/step - loss: 0.7673 - accuracy: 0.0943 - top3accuracy: 0.2313\n",
            "Epoch 6/50\n",
            "10000/10000 [==============================] - 79s 8ms/step - loss: 0.7576 - accuracy: 0.0983 - top3accuracy: 0.2398\n",
            "Epoch 7/50\n",
            "10000/10000 [==============================] - 79s 8ms/step - loss: 0.7528 - accuracy: 0.0974 - top3accuracy: 0.2410\n",
            "Epoch 8/50\n",
            "10000/10000 [==============================] - 78s 8ms/step - loss: 0.7531 - accuracy: 0.0936 - top3accuracy: 0.2302\n",
            "Epoch 9/50\n",
            "10000/10000 [==============================] - 79s 8ms/step - loss: 0.7460 - accuracy: 0.0930 - top3accuracy: 0.2318\n",
            "Epoch 10/50\n",
            "10000/10000 [==============================] - 79s 8ms/step - loss: 0.7421 - accuracy: 0.0925 - top3accuracy: 0.2328\n",
            "Epoch 11/50\n",
            "10000/10000 [==============================] - 77s 8ms/step - loss: 0.7395 - accuracy: 0.0921 - top3accuracy: 0.2330\n",
            "Epoch 12/50\n",
            "10000/10000 [==============================] - 78s 8ms/step - loss: 0.7387 - accuracy: 0.0913 - top3accuracy: 0.2309\n",
            "Epoch 13/50\n",
            "10000/10000 [==============================] - 78s 8ms/step - loss: 0.7385 - accuracy: 0.0907 - top3accuracy: 0.2285\n",
            "Epoch 14/50\n",
            "10000/10000 [==============================] - 78s 8ms/step - loss: 0.7374 - accuracy: 0.0900 - top3accuracy: 0.2274\n",
            "Epoch 15/50\n",
            "10000/10000 [==============================] - 77s 8ms/step - loss: 0.7342 - accuracy: 0.0898 - top3accuracy: 0.2299\n",
            "Epoch 16/50\n",
            "10000/10000 [==============================] - 78s 8ms/step - loss: 0.7324 - accuracy: 0.0909 - top3accuracy: 0.2310\n",
            "Epoch 17/50\n",
            "10000/10000 [==============================] - 76s 8ms/step - loss: 0.7326 - accuracy: 0.0899 - top3accuracy: 0.2292\n",
            "Epoch 18/50\n",
            "10000/10000 [==============================] - 77s 8ms/step - loss: 0.7272 - accuracy: 0.0908 - top3accuracy: 0.2291\n",
            "Epoch 19/50\n",
            "10000/10000 [==============================] - 77s 8ms/step - loss: 0.7280 - accuracy: 0.0881 - top3accuracy: 0.2246\n",
            "Epoch 20/50\n",
            "10000/10000 [==============================] - 77s 8ms/step - loss: 0.7277 - accuracy: 0.0905 - top3accuracy: 0.2284\n",
            "Epoch 21/50\n",
            "10000/10000 [==============================] - 78s 8ms/step - loss: 0.7269 - accuracy: 0.0916 - top3accuracy: 0.2324\n",
            "Epoch 22/50\n",
            "10000/10000 [==============================] - 78s 8ms/step - loss: 0.7291 - accuracy: 0.0904 - top3accuracy: 0.2298\n",
            "Epoch 23/50\n",
            "10000/10000 [==============================] - 77s 8ms/step - loss: 0.7277 - accuracy: 0.0912 - top3accuracy: 0.2292\n",
            "Epoch 24/50\n",
            "10000/10000 [==============================] - 77s 8ms/step - loss: 0.7243 - accuracy: 0.0915 - top3accuracy: 0.2296\n",
            "Epoch 25/50\n",
            "10000/10000 [==============================] - 77s 8ms/step - loss: 0.7226 - accuracy: 0.0923 - top3accuracy: 0.2325\n",
            "Epoch 26/50\n",
            "10000/10000 [==============================] - 77s 8ms/step - loss: 0.7239 - accuracy: 0.0951 - top3accuracy: 0.2342\n",
            "Epoch 27/50\n",
            "10000/10000 [==============================] - 77s 8ms/step - loss: 0.7231 - accuracy: 0.0918 - top3accuracy: 0.2312\n",
            "Epoch 28/50\n",
            "10000/10000 [==============================] - 78s 8ms/step - loss: 0.7278 - accuracy: 0.0906 - top3accuracy: 0.2283\n",
            "Epoch 29/50\n",
            "10000/10000 [==============================] - 78s 8ms/step - loss: 0.7292 - accuracy: 0.0940 - top3accuracy: 0.2319\n",
            "Epoch 30/50\n",
            "10000/10000 [==============================] - 77s 8ms/step - loss: 0.7266 - accuracy: 0.0958 - top3accuracy: 0.2371\n",
            "Epoch 31/50\n",
            "10000/10000 [==============================] - 78s 8ms/step - loss: 0.7244 - accuracy: 0.0924 - top3accuracy: 0.2333\n",
            "Epoch 32/50\n",
            "10000/10000 [==============================] - 77s 8ms/step - loss: 0.7229 - accuracy: 0.0926 - top3accuracy: 0.2311\n",
            "Epoch 33/50\n",
            "10000/10000 [==============================] - 78s 8ms/step - loss: 0.7216 - accuracy: 0.0929 - top3accuracy: 0.2336\n",
            "Epoch 34/50\n",
            "10000/10000 [==============================] - 79s 8ms/step - loss: 0.7170 - accuracy: 0.0957 - top3accuracy: 0.2358\n",
            "Epoch 35/50\n",
            "10000/10000 [==============================] - 79s 8ms/step - loss: 0.7203 - accuracy: 0.0931 - top3accuracy: 0.2342\n",
            "Epoch 36/50\n",
            "10000/10000 [==============================] - 78s 8ms/step - loss: 0.7194 - accuracy: 0.0942 - top3accuracy: 0.2319\n",
            "Epoch 37/50\n",
            "10000/10000 [==============================] - 81s 8ms/step - loss: 0.7220 - accuracy: 0.0926 - top3accuracy: 0.2319\n",
            "Epoch 38/50\n",
            "10000/10000 [==============================] - 82s 8ms/step - loss: 0.7170 - accuracy: 0.0960 - top3accuracy: 0.2368\n",
            "Epoch 39/50\n",
            "10000/10000 [==============================] - 81s 8ms/step - loss: 0.7252 - accuracy: 0.0963 - top3accuracy: 0.2356\n",
            "Epoch 40/50\n",
            "10000/10000 [==============================] - 81s 8ms/step - loss: 0.7166 - accuracy: 0.0945 - top3accuracy: 0.2316\n",
            "Epoch 41/50\n",
            "10000/10000 [==============================] - 80s 8ms/step - loss: 0.7138 - accuracy: 0.0951 - top3accuracy: 0.2322\n",
            "Epoch 42/50\n",
            "10000/10000 [==============================] - 81s 8ms/step - loss: 0.7139 - accuracy: 0.0921 - top3accuracy: 0.2267\n",
            "Epoch 43/50\n",
            "10000/10000 [==============================] - 79s 8ms/step - loss: 0.7230 - accuracy: 0.0958 - top3accuracy: 0.2336\n",
            "Epoch 44/50\n",
            "10000/10000 [==============================] - 77s 8ms/step - loss: 0.7150 - accuracy: 0.0939 - top3accuracy: 0.2291\n",
            "Epoch 45/50\n",
            "10000/10000 [==============================] - 79s 8ms/step - loss: 0.7105 - accuracy: 0.0932 - top3accuracy: 0.2290\n",
            "Epoch 46/50\n",
            "10000/10000 [==============================] - 77s 8ms/step - loss: 0.7152 - accuracy: 0.0949 - top3accuracy: 0.2281\n",
            "Epoch 47/50\n",
            "10000/10000 [==============================] - 77s 8ms/step - loss: 0.7189 - accuracy: 0.0945 - top3accuracy: 0.2273\n",
            "Epoch 48/50\n",
            "10000/10000 [==============================] - 77s 8ms/step - loss: 0.7158 - accuracy: 0.0945 - top3accuracy: 0.2282\n",
            "Epoch 49/50\n",
            "10000/10000 [==============================] - 77s 8ms/step - loss: 0.7135 - accuracy: 0.0947 - top3accuracy: 0.2289\n",
            "Epoch 50/50\n",
            "10000/10000 [==============================] - 78s 8ms/step - loss: 0.7109 - accuracy: 0.0935 - top3accuracy: 0.2248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model save"
      ],
      "metadata": {
        "id": "2tEtzpPFrUWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g4r.model.save_weights(\"/content/drive/Shareddrives/DSL_Modeling_B/model/Session-based/GRU4Rec_save/GRU4Rec_top1_weights.h5\")"
      ],
      "metadata": {
        "id": "Kk4OmBmArSCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model load"
      ],
      "metadata": {
        "id": "dvA9_zaDrZEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g4r = Gru4Rec(n_classes = dataset_train.n_items)"
      ],
      "metadata": {
        "id": "m8P3ar3yrXhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g4r.model.load_weights(\"/content/drive/Shareddrives/DSL_Modeling_B/model/Session-based/GRU4Rec_save/GRU4Rec_top1_weights.h5\")"
      ],
      "metadata": {
        "id": "D62GYhckrbtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "B-prBLpfrg8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_states = np.empty(shape = (dataset_train.n_sessions, g4r.n_layers, g4r.n_hidden)) # final states will be stored here\n",
        "final_states[:] = None\n",
        "done = [False] * dataset_train.n_sessions   # keep track of the sessions for which the last state has already been calculated\n",
        "\n",
        "stacks = [dataset_train.extract_session(i)[::-1] for i in range(g4r.batch_size)]\n",
        "next_session_id = g4r.batch_size\n",
        "batch_idx_to_session = np.arange(g4r.batch_size)   # keep track of which session is in each batch element\n",
        "X = np.empty(shape = (g4r.batch_size, 1, g4r.n_classes))\n",
        "\n",
        "g4r.model.reset_states()    # all hidden states set to 0 (starting point)\n",
        "\n",
        "n_done = 0\n",
        "while n_done < dataset_train.n_sessions:\n",
        "    for i in range(g4r.batch_size):\n",
        "        while len(stacks[i]) == 1:  # stack i is at the end\n",
        "            if not done[batch_idx_to_session[i]]:\n",
        "                # save final hidden state\n",
        "                final_states[batch_idx_to_session[i], :] = np.array([layer.states[0][i, :] for layer in g4r.model.layers if g4r._is_GRU_layer(layer)])\n",
        "                done[batch_idx_to_session[i]] = True\n",
        "                n_done += 1\n",
        "                if n_done % 100 == 0:\n",
        "                    print(\"Progress: {} / {}\".format(n_done, dataset_train.n_sessions))\n",
        "            if next_session_id >= dataset_train.n_sessions: # restart from the beginning (just to reach required batch size)\n",
        "                next_session_id = 0\n",
        "            stacks[i] = dataset_train.extract_session(next_session_id)[::-1]\n",
        "            batch_idx_to_session[i] = next_session_id\n",
        "            next_session_id += 1\n",
        "            g4r._reset_hidden(i)   # session has changed --> reset corresponding hidden state\n",
        "        X[i, 0] = stacks[i].pop()\n",
        "\n",
        "    _ = g4r.model.predict(X)   # hidden states get updated when \"predict\" is called\n",
        "\n",
        "print(\"All final hidden states calculated\")\n",
        "np.save('/content/drive/Shareddrives/DSL_Modeling_B/model/Session-based/GRU4Rec_save/final_states_top1.npy', final_states, allow_pickle = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCUrE_wTrikH",
        "outputId": "ecea1648-5d02-4b21-eb04-5a6fe3d2ad89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 100 / 4583\n",
            "Progress: 200 / 4583\n",
            "Progress: 300 / 4583\n",
            "Progress: 400 / 4583\n",
            "Progress: 500 / 4583\n",
            "Progress: 600 / 4583\n",
            "Progress: 700 / 4583\n",
            "Progress: 800 / 4583\n",
            "Progress: 900 / 4583\n",
            "Progress: 1000 / 4583\n",
            "Progress: 1100 / 4583\n",
            "Progress: 1200 / 4583\n",
            "Progress: 1300 / 4583\n",
            "Progress: 1400 / 4583\n",
            "Progress: 1500 / 4583\n",
            "Progress: 1600 / 4583\n",
            "Progress: 1700 / 4583\n",
            "Progress: 1800 / 4583\n",
            "Progress: 1900 / 4583\n",
            "Progress: 2000 / 4583\n",
            "Progress: 2100 / 4583\n",
            "Progress: 2200 / 4583\n",
            "Progress: 2300 / 4583\n",
            "Progress: 2400 / 4583\n",
            "Progress: 2500 / 4583\n",
            "Progress: 2600 / 4583\n",
            "Progress: 2700 / 4583\n",
            "Progress: 2800 / 4583\n",
            "Progress: 2900 / 4583\n",
            "Progress: 3000 / 4583\n",
            "Progress: 3100 / 4583\n",
            "Progress: 3200 / 4583\n",
            "Progress: 3300 / 4583\n",
            "Progress: 3400 / 4583\n",
            "Progress: 3500 / 4583\n",
            "Progress: 3600 / 4583\n",
            "Progress: 3700 / 4583\n",
            "Progress: 3800 / 4583\n",
            "Progress: 3900 / 4583\n",
            "Progress: 4000 / 4583\n",
            "Progress: 4100 / 4583\n",
            "Progress: 4200 / 4583\n",
            "Progress: 4300 / 4583\n",
            "Progress: 4400 / 4583\n",
            "Progress: 4500 / 4583\n",
            "All final hidden states calculated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_states = np.load('/content/drive/Shareddrives/DSL_Modeling_B/model/Session-based/GRU4Rec_save/final_states_top1.npy')\n",
        "\n",
        "g4r.model.reset_states()\n",
        "\n",
        "rem = dataset_train.n_sessions % g4r.batch_size\n",
        "if rem > 0:\n",
        "    X_test = pd.concat((X_test, X_test[:(g4r.batch_size - rem)]), axis = 0)\n",
        "\n",
        "# Calculate next item predictions for all sessions\n",
        "y_pred = np.empty(shape = (dataset_train.n_sessions, g4r.n_classes))\n",
        "y_pred[:] = None\n",
        "X = np.empty(shape = (g4r.batch_size, 1, g4r.n_classes))\n",
        "for batch_id in range(dataset_train.n_sessions // g4r.batch_size):\n",
        "    # X contains the penultimate item in the session (= last item in the training set)\n",
        "    X[:] = None\n",
        "    for i in range(g4r.batch_size):\n",
        "        X[i, :] = dataset_train.item_to_one_hot(X_test.iloc[batch_id * g4r.batch_size + i]['item'])\n",
        "    # set hidden states equal to final hidden states for sessions in the batch\n",
        "    nlg = 0\n",
        "    for nl, layer in enumerate(g4r.model.layers):\n",
        "        if g4r._is_GRU_layer(layer):\n",
        "            g4r.model.layers[nl].reset_states(final_states[batch_id * g4r.batch_size : (batch_id + 1) * g4r.batch_size, nlg, :])\n",
        "            nlg += 1\n",
        "    # objective: predict last element in the session\n",
        "    y_pred[batch_id * g4r.batch_size : (batch_id + 1) * g4r.batch_size, :] = g4r.model.predict(X)[:g4r.batch_size]\n",
        "\n",
        "y_pred = tf.constant(y_pred[:dataset_train.n_sessions], dtype = tf.float32)"
      ],
      "metadata": {
        "id": "vRQpeloQrkcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve ground truths\n",
        "y_true = np.empty(shape = (dataset_train.n_sessions, dataset_train.n_items))\n",
        "for i in range(y_true.shape[0]):\n",
        "    y_true[i, :] = dataset_train.item_to_one_hot(y_test.item.values[i])\n",
        "y_true = tf.constant(y_true, dtype = tf.float32)"
      ],
      "metadata": {
        "id": "fyadnyjirl8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc       = (tf.reduce_sum(tf.keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k = 1)) / y_true.shape[0]).numpy()\n",
        "top_3_acc = (tf.reduce_sum(tf.keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k = 3)) / y_true.shape[0]).numpy()\n",
        "\n",
        "print(\"Accuracy = {}\".format(acc))\n",
        "print(\"Top-3 accuracy = {}\".format(top_3_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SgeJA1mrpIL",
        "outputId": "ec72711f-910d-4193-b2b8-c8f0dcbb58cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 0.1047348901629448\n",
            "Top-3 accuracy = 0.23019856214523315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict value save"
      ],
      "metadata": {
        "id": "MZsRZF_srtJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_true_np = np.array(y_true)[:4580, :]\n",
        "y_pred_np = np.array(y_pred)[:4580, :]"
      ],
      "metadata": {
        "id": "XHsxeCbzrrVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true_np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kdcu4gYfryvj",
        "outputId": "cef4d31b-09d2-442b-8213-e3ea7abf5770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBOn-LEsSOZa",
        "outputId": "2eabfb34-d691-49a7-b358-f2feb2eb9248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.18234196,  0.13206947,  0.4707626 , ..., -0.30531332,\n",
              "         0.46278262, -0.6237427 ],\n",
              "       [-0.17019618, -0.5519112 ,  0.15971166, ..., -0.25626686,\n",
              "        -0.12692827, -0.7925914 ],\n",
              "       [ 0.15443835, -0.3544121 , -0.11244911, ...,  0.08300754,\n",
              "        -0.10244731, -0.40732247],\n",
              "       ...,\n",
              "       [ 0.40965822, -0.0440309 , -0.13181376, ...,  0.4221342 ,\n",
              "         1.2867311 ,  0.16569565],\n",
              "       [-0.15870696,  0.6066526 ,  2.7666235 , ...,  1.1260334 ,\n",
              "        -0.19086054, -0.5577077 ],\n",
              "       [-0.28598043, -1.2953919 ,  1.126379  , ...,  1.4687626 ,\n",
              "        -0.13356   ,  0.6174801 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true_np.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MbfRCK0UNcI",
        "outputId": "5c79a78a-17da-4933-ac69-fcebb184e1f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4580, 2397)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_np.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F527ccThrwdq",
        "outputId": "90fa0ccc-4f92-49c4-8ec9-806fed3e0a64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4580, 2397)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('/content/drive/Shareddrives/DSL_Modeling_B/model/Session-based/GRU4Rec_save/y_true_top1.npy', y_true_np, allow_pickle = False)\n",
        "np.save('/content/drive/Shareddrives/DSL_Modeling_B/model/Session-based/GRU4Rec_save/y_pred_top1.npy', y_pred_np, allow_pickle = False)"
      ],
      "metadata": {
        "id": "MFBSaQ5FrxeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test predict value save"
      ],
      "metadata": {
        "id": "GCUvewMIUx4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_true_test = np.load('/content/drive/Shareddrives/DSL_Modeling_B/model/Session-based/GRU4Rec_save/y_true_top1.npy')\n",
        "y_pred_test = np.load('/content/drive/Shareddrives/DSL_Modeling_B/model/Session-based/GRU4Rec_save/y_pred_top1.npy')"
      ],
      "metadata": {
        "id": "5k77M0vmU0e0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 설문조사 데이터는 session 4532 부터\n",
        "y_true_test = y_true_test[4532:, :]\n",
        "y_pred_test = y_pred_test[4532:, :]"
      ],
      "metadata": {
        "id": "Z6zOXMbSVBMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('/content/drive/Shareddrives/DSL_Modeling_B/model/Session-based/GRU4Rec_save/y_true_test_top1.npy', y_true_test, allow_pickle = False)\n",
        "np.save('/content/drive/Shareddrives/DSL_Modeling_B/model/Session-based/GRU4Rec_save/y_pred_test_top1.npy', y_pred_test, allow_pickle = False)"
      ],
      "metadata": {
        "id": "KLsB0cXMXPSK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}